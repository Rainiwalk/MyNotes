### 性能度量

**性能度量(Performance Measure)**：评价模型泛化能力的标准。对于不同的模型，有不同的评价标准，不同的评价标准将导致不同的评价结果。模型的好坏是相对的，取决于对于当前任务需求的完成情况。

理解：我已经有了评估划分划分还有训练误差的概念，还需要什么呢？这个和损失函数有什么区别吗，感觉就是在不同一样的定义，但内容其实说的是一个东西



理解：我懂了点，我们现在是要选择好模型，首先根据问题分析决定了用回归还是分类什么的，但这个思路下也有好多模型，这些模型的选择，就要看性能度量了



### 回归算法性能度量



回归模型的性能度量通常选用**均方误差(Mean Squared Error)**。

看个计算样例.

![image-20210803085907271](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210803085914.png)



最后就是根据两个模型的结果，第二个更小，所以第二个模型表现(性能)更好

理解：这不就是经验风险？





### 分类算法性能度量



分类算法常用的性能度量

* 错误率：**分类错误**的样本占总样本数的比例，其公式为：

  ![image-20210803090332791](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210803090332.png)

  我们以二分类为例，预测结果1或0，预测完有部分会错误，错的/总的就是错误率



* 精度：**分类正确**的样本占总样本数的比例，其公式为：

  ![image-20210803090408683](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210803090408.png)



* 查准率：预测结果为正的样本中实际值也为正的比例

  

* 查全率：实际值为正的样本中被预测为正的样本的比例



Tip：具体用哪个其实是和业务场景相关的。比如100个人里要识别出犯罪嫌疑人，假设里面只有一个人是。

如果我把所有人都看作不是犯罪嫌疑人，那么错误率其实就只有1%，精度是99%，看起来好像挺好的样子。但其实这个模型对我来讲没有用，因为你把所有人都看作不是犯罪嫌疑人，我没法通过这个模型找到犯罪嫌疑人。

这个时候可能更要看查全率。

如果100人中有5个嫌疑人，如果你预测的结果里有6个，如果这里面只有3个是真的嫌疑人，那你的查全率就是3/5 = 60%。

这个可能就更有用。



所以性能度量其实是从不同的角度来看待结果的，具体要用哪个来评估模型，其实和需求是紧密相关的。





* P-R曲线：查准率 - 查询率曲线

  

* 混淆矩阵：将预测分类结果和实际分类结果做成矩阵的形式显示

  比如如果你是01分类，那就会分成4个象限，一个象限是真实值为0，预测也为0的；别的可能是1什么的。



* ![image-20210803090613984](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210803090614.png)

  β值得不同体现了对查全率和查准率的不同倾向，其公式为：

  ![image-20210803090707944](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210803090707.png)

  P是精确度，R是召回率。

  通常会用F1 - score(β=1)，它是综合看待了模型的结果。如果你的场景没有特殊需求，那你就不用看上面那4个单点的度量，最好就用F1-score。这个要看**ROC曲线**。

  因为实际上我们在做分类时，返回的结果并不是真正的0和1，很多情况下返回的是1个概率，比如1的概率是90%什么的.  这个时候你就要设置一个罚值，默认是50%，如果返回的结果是1的概率超过50%，那就把结果置成1，否则为0.   

  当然这个罚值也是可以调整的，取不同的罚值最终结果就会不一样。

  ROC曲线就是由此而来，当你取不同的罚值，重新刷新一遍，1和0结果就会不一样，通过这个就可以做出一个ROC曲线

  

  

* 受试者特征曲线(ROC)和曲线下面积(AUC)：TPR-FPR曲线(真正例率 - 假正例率曲线)

  上面说的阈值不同结果不同画出的曲线就是这里的ROC曲线。

  这个曲线下面积可以量化不同阈值下哪个模型更优

* 代价曲线：不同类型的预测错误对结果影响不同而增加的代价(cost)，绘制

  ![image-20210803090946955](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210803090946.png)



* ....











### 聚类算法的性能度量

这个就比分类那个复杂了



* 外部指标(External Index)：将聚类结果同某个参考模型进行比较

  ![image-20210803093351499](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210803093351.png)



* 内部指标(Internal Index)：不使用参考模型直接考察聚类结果

  ![image-20210803093409644](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210803093409.png)
