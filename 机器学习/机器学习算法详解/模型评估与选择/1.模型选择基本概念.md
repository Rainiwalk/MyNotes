这里存放模型选择部分相关概念



### 误差

**误差(Error)**：是模型的预测输出值与其真实值之间的差异



其实初中物理就学过误差了，测量东西，使用测量工具方法不恰当，人读出差出一点点等等都会带来误差。这种通常叫做**测量误差**。

其实还有另外一种误差，比如测量用的尺子被开水烫过有些扭曲，在测量长度时也会出现问题。这个就是**系统误差**。

与误差相对的概念还有一个是：**错误**。

但他俩区别是比较大的，比如测量是10cm，我读成了10m，那这就是错误。



**训练(Training)**：通过已知的样本数据进行学习，从而得到模型的过程。有时也把它叫做学习。

**训练误差(Training Error)**：模型作用于训练集时的误差。我用数据搞出一个模型，去预测原有数据，得到的结果和真实数据可能仍然存在差异，就是训练误差。



**泛化(Generalize)：**由具体的、个别的扩大为一般的，即从特殊到一般，称为泛化。对机器学习的模型来讲，泛化是指模型作用于新的样本数据(非训练集)。

理解：感觉和Java那里的泛型有点类似的

举个例子，我拿来两个苹果，问有几个，1+1=2。后来我拿来一个苹果和一个梨，还是问，就是泛化。这就把学到的1+1=2应用于新的东西了。



**泛化误差(Generalization Error)**：模型作用于新的样本数据时的误差

理解：这个和那个训练误差就不太一样，这个是把模型用于新的，那个是用于旧的数据



![image-20210802101046695](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210802101046.png)

可以看出层次





### 欠拟合和过拟合

**模拟容量(Model Capacity)**：是指其拟合各种模型的能力

**过拟合(Overfitting)**：是指某个模型在训练集上表现很好，但是在新样本上表现差。**模型将训练集的特征学习的太好，导致一些非普遍规律被模型接纳和体现，从而在训练集上表现好，但是对于新样本表现差。**反之则称为**欠拟合(Underfitting)**，即模型对训练集的一般性质学习较差，模型作用于训练集时表现不好。

机器学习过程中将有很多时间会放到和过拟合的斗争上去

理解：哈哈，就是你做例题做得非常好，但是换个题就一点也不会做了，原来我之前一直在过拟合嘛🤣。至于欠拟合，你连例题都不会，根本一无是处，笑死。

欠拟合的话，我们可以会通过增加学习量，让模型更加负责或更换一些算法来解决。相对于过拟合其实算比较容易的部分。



![image-20210802112247252](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210802112247.png)







### 模型选择

**模型选择(Model Selection)：**针对某个具体的任务，通常会有多种模型可供选择，对同一个模型也会有多组参数，可以通过分析、评估模型的泛化误差，选择泛化误差最小的模型。



看这样一个图，横坐标是模型容量，纵坐标是误差。

![image-20210802112626097](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210802112626.png)



可以看到：

蓝色线是训练误差，绿线是泛化误差。

可以发现随着训练进行，蓝色线越来越接近于0，说明训练误差越来越小。

绿色线是泛化误差，它会有一个波动，开始是在下降的，但是后来又上升了。

我们选择模型要选择红色竖线对应的位置，这里对应泛化误差最小，训练误差也比较小。

可以看到在红线左侧就是欠拟合区域，右侧就是过拟合区域。

这个图就很好反映了训练过程中误差发生的变化。



