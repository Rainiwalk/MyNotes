### 机器学习算法三要素

机器学习方法通常都是由模型、策略和算法三部分构成：方法 = 模型 + 策略 + 算法



![image-20210801165256141](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801165256.png)



模型：输入空间到输出空间的映射关系。学习的过程即为从假设空间中搜索适合当前数据的假设

策略：从假设空间众多的假设中选择到最优的模型的学习标准或规则

算法：学习模型的具体的计算方法，通常是求解最优化问题



理解：现在来看，我有不同的学习模型，比如一维线性，二维线性，这都是存在于假设空间的不同假设，首先确定的这个是个比较宏观的东西。策略就是找到用哪个假设的策略。等确定是这个假设，比如 y = kx + b，之后主题再去决定这个假设的细节，比如参数是多少，就是算法的事了。算法就是把抽象模型具象化。





### 模型

模型：输入空间到输出空间的映射关系。学习过程即为从假设空间中搜索适合当前数据的假设。



**就是分析当前需要解决的问题，确定模型类型。**

理解：就是一个现实问题很具体的时候，看起来是很复杂的，你可能看不明白关系。现在你会的也就是数学课本上讲的一些经典模型。此时想要解决问题就要把它与现有的数学模型建立起关系，也就是可以抽象抽象看看，看看复杂事件背后的数学本质，如果能对应上数学模型，那你就可以迁移用数学来建模了。



![image-20210801170351861](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801170351.png)



预测分类：一个带有很多特征的水果，买还是不买，分成了两类

预测取值：比如根据父亲身高取预测孩子身高

发现结构：有很多客户，自己去发现分类

发现异常数据：比如防欺诈

等等...







### 策略

策略：从假设空间众多的假设中选择到最优的模型的学习标准或规则



要从假设空间中选择一个最合适的模型出来，需要解决以下问题：

* 评估某个模型对单个训练样本的效果
* 评估某个模型对训练集的整体效果
* 评估某个模型对包括训练集、预测集在内的所有数据的整体效果





定义几个指标来衡量上述问题：

* 损失函数：0-1损失函数、平方损失函数、绝对损失函数、对数损失函数等
* 风险函数：经验风险、期望风险、结构风险



基本策略(基于指标来选模型的策略)

经验风险最小(EMR：Empirical Risk Minimization)

结构风险最小(SRM：Structural Risk Minimizaion)







#### 损失函数

损失函数(Loss Function)：用来衡量预测结果和真实结果之间的差距，其值越小，代表预测结果和真实结果越一致。通常是一个**非负实值**函数。通过各种方式缩小损失函数的过程被称作**优化**。损失函数记作 L( Y，f(x) )，Y就是真实值，f(x)就是模型的预测取值。



还是拿父亲和孩子身高预测举例，比如父亲1.67，孩子1.69。但是我模型预测值为1.68，那68和69就会有一个差距。

那我们判断这个模型有多好就可以借助损失函数，把真实值和预测值的差都累加起来(这里差只是一个泛泛概念，具体是绝对值还是平方还要再说，求和是因为当然要考虑对所有数据而不是某个数据)。

这个损失越小，就可以说模型预测的结果越接近真实值，模型越好。



损失函数常见类型



* **0-1损失函数(0-1 LF)**：预测值和实际值精确相等则"没有损失"为0，否则意味着"完全损失"，为1。预测值和实际值精确相等其实有些过于严格，采用两者差小于某个阈值的方式也许更好。

  ![image-20210801181707917](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801181707.png)

  这里也就可以知道机器学习应用中**有些东西其实是和业务场景息息相关的**。

  如果我预测一个很会不会买我的东西，要求不那么严格，那就用第二个。

  如果是检测会不会得癌症，要求十分精确，那就要用第一个了。

  而实际上，第一个模型就相当于第二个模型T=0的一个特殊情况。

  

* **绝对值损失函数(Absolute LF)**：预测结果于真实结果差的绝对值。简单易懂，但是计算不方便(很多运算有了绝对值就很麻烦)。

  ![image-20210801182452375](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801182452.png)

  

* **平方损失函数(Quadratic LF)**：预测结果与真实结果差的平方

  因为计算绝对值不太方便，所以使用平方来去除符号影响。

  ![image-20210801182700862](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801182700.png)

  优势：

  * 每个样本的误差都是正的，累加不会被抵消

  * 平方对于大误差的惩罚大于小误差

    0.1^2 = 0.01   2^2 = 4

  * 数学计算简单、友好，导数为一次函数(通常我们做损失函数优化都要求导看它损失函数的变化率，平方就很友好了，绝对值就很麻烦)

    

  ![image-20210801183122398](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801183122.png)



* **对数损失函数(Logarithmic LF)** 或 **对数似然损失函数(log-likehood loss function)**

  对数函数具有单调性，在求最优化问题时，结果与原始目标一致。

  而且可将乘法转化为加法，除法转换剑法，简化计算

  ![image-20210801193643358](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801193643.png)



* 指数损失函数(Exponential LF)：单调性、非负性的优良性质，使得越接近正确结果误差越小

  ![image-20210801193747897](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801193747.png)



* 折页损失函数(Hinge LF)：也称铰链损失，对于判定边界附近的点的惩罚力度较高，常见于SVM

  ![image-20210801193856251](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801193856.png)



可以看到不同损失函数表现是不一样的。

![image-20210801193946166](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801193946.png)



不同损失函数有不同的特点，适用于不同的场景：

* 0-1：理想状况模型
* Log：逻辑回归、交叉熵
* Squared：线性回归
* Exponential(指数)：AdaBoosting
* Hinge：SVM、soft margin







#### 经验风险 VS 风险函数(期望风险)

经验风险(Empirical Risk)：损失函数度量了单个样本的预测结果，要想衡量整个训练集的预测值与真实值的差距，将整个训练集所有记录均进行一次预测，求取损失函数，将所有值累加，即为经验风险。经验风险越小说明模型f(x)对训练集的拟合程度越好。

公式：

![image-20210801194707035](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801194707.png)



理解：其实就是对所有数据求损失函数，结果加起来求平均



风险函数(Risk Function)：又称期望损失、**期望风险**。所有数据集(包括训练集和预测集，遵循联合分布P(X,Y) ）的损失函数的期望值。

公式：

![image-20210801195019938](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801195019.png)



理解：这个公式可以不用管，我们了解有这个东西就ok,因为它也没法算



经验风险 vs 期望风险

* 期望风险是模型对全局(所有数据集，甚至包括预测集)的效果；经验风险是模型对**局部(训练集)**的效果

* 期望风险往往无法计算，即联合分布P(X,Y)通常是未知的；但是经验风险可以计算

* 当训练集**足够大**时，经验风险可以替代期望风险，即局部最优代替全局最优

  理解：哦哦哦，全局最优其实是概率论那里一个理论概念，其实很难达到，我父母也就是尽量去拟合，这里似乎也是那样



实际上，如果我们可以计算期望风险的话，它是最优的，是对于全局数据的，但是是不可能的，我们只能用经验风险。





**经验风险的问题**

在样本较小时，仅关注经验风险，很容易导致过拟合(对当前样本数据效果非常好，但对新的数据预测效果很差)。

举个例子,看这样一个找拟合函数的过程

![image-20210801202148009](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801202148.png)



发现到六次模型，已经完全拟合了：因为总共有7个值，两个变量，一个六次方模型一定可以完美拟合每一个点(经验风险值为0). --- **六次函数一定能完美拟合七个点(这是什么数学定理吗？)**

所以此时经验风险最小就是那个六次模型。



但是，经验风险低，模型未必就一定好。

来看我的总的数据集(数据+预测)和运算.

![image-20210801202423231](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801202423.png)



这样来看，一次函数在整个数据集的预测上才是最低的，是1.15.

那个在经验集表现风险最小的六次函数，反而全局风险是最大的，782.35，那这就是发生了严重的**过拟合**。



所以现在就是，我没法算最好的期望风险，但是我的经验风险又无法通过比较值来选择最优的那个(因为有可能过拟合)。

现在要怎么办呢？

我们就引入了结构风险的概念。





#### 结构风险

结构风险(Structural Risk)：在经验风险的基础上，增加一个正则化项(Regularizer)或者叫叫做惩罚项(Penalty Term)。



公式(就是在经验风险后面加了东西)：

![image-20210801202947889](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210801202947.png)

其中λ为一个大于0的系数，J(f)表示模型对f(x)的复杂度。



这个λJ(f)是一个正值，所以就会让原有的值更大，也就是风险更大。

而不同的模型复杂度不一样，对应惩罚力度就不一样。就会对经验风险做出一个调整。





**结构风险 vs 经验风险：**

* 经验风险越小，模型决策函数越复杂，其包含的参数越多

  比如上面一次和六次模型的例子

* 当经验风险函数小到一定程度就出现了过拟合现象

* 防止过拟合现象的方式，就要降低决策函数的复杂度，让惩罚项J(f)最小化

* 需要同时保证经验风险函数和模型决策函数的复杂度都达到最小化

  也就是**既要保证模型对整个数据拟合还不错，同时又要保证模型不要太复杂，出现过拟合**

* 把两个式子融合成一个式子得到结构风险函数然后再对这个结构风险函数进行最小化





接着来看一个例子.

![image-20210802090242382](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210802090249.png)



附：那个惩罚项取的是参数绝对值求和(好像不算常数项)。

按照这里的形式，可以说越复杂的模型，参数越多，类似多项式。比如下面这个，θ和公式的概念一样。

![image-20210802090721248](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210802090721.png)



从图中就可以看出对于训练集的经验风险、结构风险，还有加上预测集后的结果。

可以看出：如果没有预测集，如果按照经验风险，我会选择二元，但是按照结构风险，我就会选择一元。最后加上预测集我们进行检验，发现确实一元最好。这就说明结构风险确实比经验风险优越。



问：为什么有了预测集之后，你只看经验风险而不看结构风险了？

答：因为有了预测集之后，相当于我开上帝视角了，数据全了，这是经验风险就等价于期望风险了。





**正则化项计算样例**

![image-20210802091658027](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210802091658.png)





**范数**

**就是指那个规则化函数λJ(f)。**

它有多种选择，一般地，它是模型复杂度的单调递增函数，模型越复杂，该函数的值就越大，惩罚力度相应的越大。

通常用**模型的参数向量的范数**作为惩罚项。

常用的有零范数、一范数、二范数、迹范数、Frobenius范数和核范数等等。



范数(Norm)：数学中的一种基本概念，它定义在赋范线性空间中，

满足

* 非负性
* 齐次性
* 三角不等式等条件的量



常常用来度量向量的长度或者大小。

计算公式

![image-20210802092407720](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210802092407.png)

P级的范数就等于X^p加起来开p次方



![image-20210802092538832](https://raw.githubusercontent.com/Rainiwalk/Rain_image/main/2021/20210802092538.png)

解释：

L0范数不太常见，结果是它的序号(下标)

L1范数就是绝对值

L2范数就是平方和开方，其实就是它的模



L0范数：非0元素的个数。如果你使用L0范数作为惩罚项，那就是你期望模型中的参数大部分为0，即让参数是稀疏的。

L1范数：各个元素绝对值之和。如果你使用L1范数作为惩罚项，就会使参数稀疏(就是里面有些项之间就没有了，如果用它，复杂模型中有些项参数就会被搞成0)。L1也被称为稀疏规则算子。

L2范数：各元素的平方和求平方根，使得每个元素都很小，但不会等于0，而是接近0。就是你使用L2范数做惩罚项的话，如果你有5项，通常这5项都会被保留，但是有一些项的参数会被调的非常小，接近于0但不等于0。



举个例子，模型有5项，如果用L0，它可能把其中4项都搞成0，就剩一个。L1可能把几个系数搞成0，L2是都还在，但有些系数非常小接近于0.





理解：暂且不要纠结这个













